{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/evergreen/Documents/GitHub/classification/code/__old'"
      ],
      "text/latex": [
       "'/Users/evergreen/Documents/GitHub/classification/code/\\_\\_old'"
      ],
      "text/markdown": [
       "'/Users/evergreen/Documents/GitHub/classification/code/__old'"
      ],
      "text/plain": [
       "[1] \"/Users/evergreen/Documents/GitHub/classification/code/__old\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"abcrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               _                           \n",
       "platform       x86_64-apple-darwin15.6.0   \n",
       "arch           x86_64                      \n",
       "os             darwin15.6.0                \n",
       "system         x86_64, darwin15.6.0        \n",
       "status                                     \n",
       "major          3                           \n",
       "minor          5.2                         \n",
       "year           2018                        \n",
       "month          12                          \n",
       "day            20                          \n",
       "svn rev        75870                       \n",
       "language       R                           \n",
       "version.string R version 3.5.2 (2018-12-20)\n",
       "nickname       Eggshell Igloo              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Library/Frameworks/R.framework/Resources'"
      ],
      "text/latex": [
       "'/Library/Frameworks/R.framework/Resources'"
      ],
      "text/markdown": [
       "'/Library/Frameworks/R.framework/Resources'"
      ],
      "text/plain": [
       "[1] \"/Library/Frameworks/R.framework/Resources\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.home() #using non-anaconda build, which is more stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abcrf demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Length Class      Mode   \n",
       "modindex 10000  factor     numeric\n",
       "param        7  data.frame list   \n",
       "sumsta      48  data.frame list   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "10000"
      ],
      "text/latex": [
       "10000"
      ],
      "text/markdown": [
       "10000"
      ],
      "text/plain": [
       "[1] 10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10000</li>\n",
       "\t<li>7</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10000\n",
       "\\item 7\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10000\n",
       "2. 7\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10000     7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>10000</li>\n",
       "\t<li>48</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 10000\n",
       "\\item 48\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 10000\n",
       "2. 48\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 10000    48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(snp)\n",
    "summary(snp)\n",
    "length(snp$modindex)\n",
    "dim(snp$param)\n",
    "dim(snp$sumsta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modindex\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>1</dt>\n",
       "\t\t<dd>3328</dd>\n",
       "\t<dt>2</dt>\n",
       "\t\t<dd>3352</dd>\n",
       "\t<dt>3</dt>\n",
       "\t\t<dd>3320</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 3328\n",
       "\\item[2] 3352\n",
       "\\item[3] 3320\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   33282\n",
       ":   33523\n",
       ":   3320\n",
       "\n"
      ],
      "text/plain": [
       "   1    2    3 \n",
       "3328 3352 3320 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "param\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       N1              N2              N3              ta       \n",
       " Min.   :  103   Min.   :  106   Min.   :  109   Min.   :   13  \n",
       " 1st Qu.: 7684   1st Qu.: 7665   1st Qu.: 7668   1st Qu.: 4071  \n",
       " Median :15089   Median :15007   Median :15292   Median : 8902  \n",
       " Mean   :15137   Mean   :15015   Mean   :15167   Mean   :10019  \n",
       " 3rd Qu.:22680   3rd Qu.:22594   3rd Qu.:22760   3rd Qu.:15056  \n",
       " Max.   :29999   Max.   :30000   Max.   :29999   Max.   :29785  \n",
       "                                                                \n",
       "       ts              N4              r        \n",
       " Min.   :  329   Min.   :  106   Min.   :0.050  \n",
       " 1st Qu.:15012   1st Qu.: 7392   1st Qu.:0.280  \n",
       " Median :21168   Median :14797   Median :0.503  \n",
       " Mean   :19980   Mean   :14974   Mean   :0.505  \n",
       " 3rd Qu.:25916   3rd Qu.:22451   3rd Qu.:0.733  \n",
       " Max.   :29999   Max.   :30000   Max.   :0.950  \n",
       "                                 NA's   :6680   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sumsta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'HP0_1'</li>\n",
       "\t<li>'HP0_2'</li>\n",
       "\t<li>'HP0_3'</li>\n",
       "\t<li>'HM1_1'</li>\n",
       "\t<li>'HM1_2'</li>\n",
       "\t<li>'HM1_3'</li>\n",
       "\t<li>'HV1_1'</li>\n",
       "\t<li>'HV1_2'</li>\n",
       "\t<li>'HV1_3'</li>\n",
       "\t<li>'HMO_1'</li>\n",
       "\t<li>'HMO_2'</li>\n",
       "\t<li>'HMO_3'</li>\n",
       "\t<li>'FP0_1.2'</li>\n",
       "\t<li>'FP0_1.3'</li>\n",
       "\t<li>'FP0_2.3'</li>\n",
       "\t<li>'FM1_1.2'</li>\n",
       "\t<li>'FM1_1.3'</li>\n",
       "\t<li>'FM1_2.3'</li>\n",
       "\t<li>'FV1_1.2'</li>\n",
       "\t<li>'FV1_1.3'</li>\n",
       "\t<li>'FV1_2.3'</li>\n",
       "\t<li>'FMO_1.2'</li>\n",
       "\t<li>'FMO_1.3'</li>\n",
       "\t<li>'FMO_2.3'</li>\n",
       "\t<li>'NP0_1.2'</li>\n",
       "\t<li>'NP0_1.3'</li>\n",
       "\t<li>'NP0_2.3'</li>\n",
       "\t<li>'NM1_1.2'</li>\n",
       "\t<li>'NM1_1.3'</li>\n",
       "\t<li>'NM1_2.3'</li>\n",
       "\t<li>'NV1_1.2'</li>\n",
       "\t<li>'NV1_1.3'</li>\n",
       "\t<li>'NV1_2.3'</li>\n",
       "\t<li>'NMO_1.2'</li>\n",
       "\t<li>'NMO_1.3'</li>\n",
       "\t<li>'NMO_2.3'</li>\n",
       "\t<li>'AP0_1_2.3'</li>\n",
       "\t<li>'AP0_2_1.3'</li>\n",
       "\t<li>'AP0_3_1.2'</li>\n",
       "\t<li>'AM1_1_2.3'</li>\n",
       "\t<li>'AM1_2_1.3'</li>\n",
       "\t<li>'AM1_3_1.2'</li>\n",
       "\t<li>'AV1_1_2.3'</li>\n",
       "\t<li>'AV1_2_1.3'</li>\n",
       "\t<li>'AV1_3_1.2'</li>\n",
       "\t<li>'AMO_1_2.3'</li>\n",
       "\t<li>'AMO_2_1.3'</li>\n",
       "\t<li>'AMO_3_1.2'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'HP0\\_1'\n",
       "\\item 'HP0\\_2'\n",
       "\\item 'HP0\\_3'\n",
       "\\item 'HM1\\_1'\n",
       "\\item 'HM1\\_2'\n",
       "\\item 'HM1\\_3'\n",
       "\\item 'HV1\\_1'\n",
       "\\item 'HV1\\_2'\n",
       "\\item 'HV1\\_3'\n",
       "\\item 'HMO\\_1'\n",
       "\\item 'HMO\\_2'\n",
       "\\item 'HMO\\_3'\n",
       "\\item 'FP0\\_1.2'\n",
       "\\item 'FP0\\_1.3'\n",
       "\\item 'FP0\\_2.3'\n",
       "\\item 'FM1\\_1.2'\n",
       "\\item 'FM1\\_1.3'\n",
       "\\item 'FM1\\_2.3'\n",
       "\\item 'FV1\\_1.2'\n",
       "\\item 'FV1\\_1.3'\n",
       "\\item 'FV1\\_2.3'\n",
       "\\item 'FMO\\_1.2'\n",
       "\\item 'FMO\\_1.3'\n",
       "\\item 'FMO\\_2.3'\n",
       "\\item 'NP0\\_1.2'\n",
       "\\item 'NP0\\_1.3'\n",
       "\\item 'NP0\\_2.3'\n",
       "\\item 'NM1\\_1.2'\n",
       "\\item 'NM1\\_1.3'\n",
       "\\item 'NM1\\_2.3'\n",
       "\\item 'NV1\\_1.2'\n",
       "\\item 'NV1\\_1.3'\n",
       "\\item 'NV1\\_2.3'\n",
       "\\item 'NMO\\_1.2'\n",
       "\\item 'NMO\\_1.3'\n",
       "\\item 'NMO\\_2.3'\n",
       "\\item 'AP0\\_1\\_2.3'\n",
       "\\item 'AP0\\_2\\_1.3'\n",
       "\\item 'AP0\\_3\\_1.2'\n",
       "\\item 'AM1\\_1\\_2.3'\n",
       "\\item 'AM1\\_2\\_1.3'\n",
       "\\item 'AM1\\_3\\_1.2'\n",
       "\\item 'AV1\\_1\\_2.3'\n",
       "\\item 'AV1\\_2\\_1.3'\n",
       "\\item 'AV1\\_3\\_1.2'\n",
       "\\item 'AMO\\_1\\_2.3'\n",
       "\\item 'AMO\\_2\\_1.3'\n",
       "\\item 'AMO\\_3\\_1.2'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'HP0_1'\n",
       "2. 'HP0_2'\n",
       "3. 'HP0_3'\n",
       "4. 'HM1_1'\n",
       "5. 'HM1_2'\n",
       "6. 'HM1_3'\n",
       "7. 'HV1_1'\n",
       "8. 'HV1_2'\n",
       "9. 'HV1_3'\n",
       "10. 'HMO_1'\n",
       "11. 'HMO_2'\n",
       "12. 'HMO_3'\n",
       "13. 'FP0_1.2'\n",
       "14. 'FP0_1.3'\n",
       "15. 'FP0_2.3'\n",
       "16. 'FM1_1.2'\n",
       "17. 'FM1_1.3'\n",
       "18. 'FM1_2.3'\n",
       "19. 'FV1_1.2'\n",
       "20. 'FV1_1.3'\n",
       "21. 'FV1_2.3'\n",
       "22. 'FMO_1.2'\n",
       "23. 'FMO_1.3'\n",
       "24. 'FMO_2.3'\n",
       "25. 'NP0_1.2'\n",
       "26. 'NP0_1.3'\n",
       "27. 'NP0_2.3'\n",
       "28. 'NM1_1.2'\n",
       "29. 'NM1_1.3'\n",
       "30. 'NM1_2.3'\n",
       "31. 'NV1_1.2'\n",
       "32. 'NV1_1.3'\n",
       "33. 'NV1_2.3'\n",
       "34. 'NMO_1.2'\n",
       "35. 'NMO_1.3'\n",
       "36. 'NMO_2.3'\n",
       "37. 'AP0_1_2.3'\n",
       "38. 'AP0_2_1.3'\n",
       "39. 'AP0_3_1.2'\n",
       "40. 'AM1_1_2.3'\n",
       "41. 'AM1_2_1.3'\n",
       "42. 'AM1_3_1.2'\n",
       "43. 'AV1_1_2.3'\n",
       "44. 'AV1_2_1.3'\n",
       "45. 'AV1_3_1.2'\n",
       "46. 'AMO_1_2.3'\n",
       "47. 'AMO_2_1.3'\n",
       "48. 'AMO_3_1.2'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"HP0_1\"     \"HP0_2\"     \"HP0_3\"     \"HM1_1\"     \"HM1_2\"     \"HM1_3\"    \n",
       " [7] \"HV1_1\"     \"HV1_2\"     \"HV1_3\"     \"HMO_1\"     \"HMO_2\"     \"HMO_3\"    \n",
       "[13] \"FP0_1.2\"   \"FP0_1.3\"   \"FP0_2.3\"   \"FM1_1.2\"   \"FM1_1.3\"   \"FM1_2.3\"  \n",
       "[19] \"FV1_1.2\"   \"FV1_1.3\"   \"FV1_2.3\"   \"FMO_1.2\"   \"FMO_1.3\"   \"FMO_2.3\"  \n",
       "[25] \"NP0_1.2\"   \"NP0_1.3\"   \"NP0_2.3\"   \"NM1_1.2\"   \"NM1_1.3\"   \"NM1_2.3\"  \n",
       "[31] \"NV1_1.2\"   \"NV1_1.3\"   \"NV1_2.3\"   \"NMO_1.2\"   \"NMO_1.3\"   \"NMO_2.3\"  \n",
       "[37] \"AP0_1_2.3\" \"AP0_2_1.3\" \"AP0_3_1.2\" \"AM1_1_2.3\" \"AM1_2_1.3\" \"AM1_3_1.2\"\n",
       "[43] \"AV1_1_2.3\" \"AV1_2_1.3\" \"AV1_3_1.2\" \"AMO_1_2.3\" \"AMO_2_1.3\" \"AMO_3_1.2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message(\"modindex\")\n",
    "summary(snp$modindex)\n",
    "message(\"param\")\n",
    "summary(snp$param)\n",
    "message(\"sumsta\")\n",
    "names(snp$sumsta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " abcrf(formula = modindex ~ ., data = data1, ntree = 100) \n",
       "includes the axes of a preliminary LDA\n",
       "\n",
       "Number of simulations: 1\n",
       "Out-of-bag prior error rate: 22.8%\n",
       "\n",
       "Confusion matrix:\n",
       "    1   2   3 class.error\n",
       "1 156   6  22   0.1521739\n",
       "2   6 123  22   0.1854305\n",
       "3  28  30 107   0.3515152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modindex <- snp$modindex[1:500]\n",
    "sumsta <- snp$sumsta[1:500,]\n",
    "data1 <- data.frame(modindex, sumsta)\n",
    "model.rf1 <- abcrf(modindex~., data = data1, ntree=100)\n",
    "model.rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " abcrf(formula = modindex ~ ., data = data1, group = list(c(\"1\", \"2\"), \"3\"), ntree = 100) \n",
       "includes the axes of a preliminary LDA\n",
       "\n",
       "Number of simulations: 1\n",
       "Out-of-bag prior error rate: 20%\n",
       "\n",
       "Confusion matrix:\n",
       "    g1 g2 class.error\n",
       "g1 309 26  0.07761194\n",
       "g2  74 91  0.44848485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.rf2 <- abcrf(modindex~., data = data1, group = list(c(\"1\",\"2\"),\"3\"), ntree=100)\n",
    "model.rf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  selected model votes model1 votes model2 votes model3 post.proba\n",
       "1              3            7            4           89  0.9450000\n",
       "2              2            7           55           38  0.8146667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(snp)\n",
    "modindex <- snp$modindex[1:500]\n",
    "sumsta <- snp$sumsta[1:500,]\n",
    "data1 <- data.frame(modindex, sumsta)\n",
    "model.rf <- abcrf(modindex~., data1, ntree=100)\n",
    "data(snp.obs)\n",
    "predict(model.rf, snp.obs, data1, ntree=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (formula, data, group = list(), lda = TRUE, ntree = 500, \n",
       "<span style=white-space:pre-wrap>    sampsize = min(1e+05, nrow(data)), paral = FALSE, ncores = if (paral) max(detectCores() - </span>\n",
       "<span style=white-space:pre-wrap>        1, 1) else 1, ...) </span>\n",
       "{\n",
       "<span style=white-space:pre-wrap>    if (!inherits(formula, \"formula\")) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"abcrf.formula is only for formula objects\")</span>\n",
       "<span style=white-space:pre-wrap>    if (!inherits(data, \"data.frame\")) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"data needs to be a data.frame object\")</span>\n",
       "<span style=white-space:pre-wrap>    if (is.na(ncores)) {</span>\n",
       "<span style=white-space:pre-wrap>        warning(\"Unable to automatically detect the number of CPU cores, \\n1 CPU core will be used or please specify ncores.\")</span>\n",
       "<span style=white-space:pre-wrap>        ncores &lt;- 1</span>\n",
       "<span style=white-space:pre-wrap>    }</span>\n",
       "<span style=white-space:pre-wrap>    if ((!is.logical(paral)) || (length(paral) != 1L)) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"paral should be TRUE or FALSE\")</span>\n",
       "<span style=white-space:pre-wrap>    if (!is.list(group)) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"group needs to be a list\")</span>\n",
       "<span style=white-space:pre-wrap>    mf &lt;- match.call(expand.dots = FALSE)</span>\n",
       "<span style=white-space:pre-wrap>    m &lt;- match(c(\"formula\", \"data\"), names(mf))</span>\n",
       "<span style=white-space:pre-wrap>    mf &lt;- mf[c(1L, m)]</span>\n",
       "<span style=white-space:pre-wrap>    mf[[1L]] &lt;- as.name(\"model.frame\")</span>\n",
       "<span style=white-space:pre-wrap>    mf &lt;- eval(mf, parent.frame())</span>\n",
       "<span style=white-space:pre-wrap>    if (!is.factor(model.response(mf))) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"response should be a factor containing the model indexes\")</span>\n",
       "<span style=white-space:pre-wrap>    if (nrow(data) == 0L || is.null(nrow(data))) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"no simulation in the reference table (response, sumstat)\")</span>\n",
       "<span style=white-space:pre-wrap>    if ((!is.logical(lda)) &amp;&amp; (length(lda) != 1L)) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"lda should be TRUE or FALSE\")</span>\n",
       "<span style=white-space:pre-wrap>    if (length(group) != 0) {</span>\n",
       "<span style=white-space:pre-wrap>        ngroup &lt;- length(group)</span>\n",
       "<span style=white-space:pre-wrap>        varn &lt;- formula[[2]]</span>\n",
       "<span style=white-space:pre-wrap>        data[[as.character(varn)]] &lt;- as.vector(data[[as.character(varn)]])</span>\n",
       "<span style=white-space:pre-wrap>        allmod &lt;- unique(data[[as.character(varn)]])</span>\n",
       "<span style=white-space:pre-wrap>        for (k in 1:ngroup) for (l in 1:length(group[[k]])) data[[as.character(varn)]][which(data[[as.character(varn)]] == </span>\n",
       "<span style=white-space:pre-wrap>            group[[k]][l])] &lt;- paste(\"g\", k, sep = \"\")</span>\n",
       "<span style=white-space:pre-wrap>        if (!setequal(allmod, unlist(group))) {</span>\n",
       "<span style=white-space:pre-wrap>            diffe &lt;- setdiff(allmod, unlist(group))</span>\n",
       "<span style=white-space:pre-wrap>            for (l in 1:length(diffe)) data &lt;- data[-which(data[[as.character(varn)]] == </span>\n",
       "<span style=white-space:pre-wrap>                diffe[l]), ]</span>\n",
       "<span style=white-space:pre-wrap>        }</span>\n",
       "<span style=white-space:pre-wrap>        data[[as.character(varn)]] &lt;- as.factor(data[[as.character(varn)]])</span>\n",
       "<span style=white-space:pre-wrap>    }</span>\n",
       "<span style=white-space:pre-wrap>    if (lda) {</span>\n",
       "<span style=white-space:pre-wrap>        model.lda &lt;- lda(formula, data)</span>\n",
       "<span style=white-space:pre-wrap>        data &lt;- cbind(data, as.matrix(predict(model.lda, data)$x))</span>\n",
       "<span style=white-space:pre-wrap>    }</span>\n",
       "<span style=white-space:pre-wrap>    else {</span>\n",
       "<span style=white-space:pre-wrap>        model.lda &lt;- NULL</span>\n",
       "<span style=white-space:pre-wrap>    }</span>\n",
       "<span style=white-space:pre-wrap>    m &lt;- names(match.call(expand.dots = TRUE))</span>\n",
       "<span style=white-space:pre-wrap>    if ((!\"sampsize\" %in% m) &amp;&amp; (nrow(data) &lt;= 15)) </span>\n",
       "<span style=white-space:pre-wrap>        sampsize &lt;- as.integer(sampsize/10)</span>\n",
       "<span style=white-space:pre-wrap>    if (sampsize &gt; nrow(data)) </span>\n",
       "<span style=white-space:pre-wrap>        stop(\"sampsize too large\")</span>\n",
       "<span style=white-space:pre-wrap>    model.rf &lt;- ranger(formula, data, num.trees = ntree, sample.fraction = sampsize/nrow(data), </span>\n",
       "<span style=white-space:pre-wrap>        num.threads = ncores, keep.inbag = TRUE, importance = \"impurity\", </span>\n",
       "<span style=white-space:pre-wrap>        ...)</span>\n",
       "<span style=white-space:pre-wrap>    class.error = vector()</span>\n",
       "<span style=white-space:pre-wrap>    for (i in 1:nrow(model.rf$confusion.matrix)) {</span>\n",
       "<span style=white-space:pre-wrap>        rowSum &lt;- sum(model.rf$confusion.matrix[i, ])</span>\n",
       "<span style=white-space:pre-wrap>        accurate &lt;- diag(model.rf$confusion.matrix)[i]</span>\n",
       "<span style=white-space:pre-wrap>        error &lt;- rowSum - accurate</span>\n",
       "<span style=white-space:pre-wrap>        class.error[i] &lt;- error/rowSum</span>\n",
       "<span style=white-space:pre-wrap>    }</span>\n",
       "<span style=white-space:pre-wrap>    model.rf$confusion.matrix &lt;- cbind(model.rf$confusion.matrix, </span>\n",
       "<span style=white-space:pre-wrap>        class.error)</span>\n",
       "<span style=white-space:pre-wrap>    colnames(model.rf$confusion.matrix) &lt;- c(paste(model.rf$forest$levels), </span>\n",
       "<span style=white-space:pre-wrap>        \"class.error\")</span>\n",
       "<span style=white-space:pre-wrap>    model.rf$model.rf</span>\n",
       "<span style=white-space:pre-wrap>    cl &lt;- match.call()</span>\n",
       "<span style=white-space:pre-wrap>    cl[[1]] &lt;- as.name(\"abcrf\")</span>\n",
       "<span style=white-space:pre-wrap>    x &lt;- list(call = cl, lda = lda, formula = formula, group = group, </span>\n",
       "<span style=white-space:pre-wrap>        model.rf = model.rf, model.lda = model.lda, prior.err = model.rf$prediction.error)</span>\n",
       "<span style=white-space:pre-wrap>    class(x) &lt;- \"abcrf\"</span>\n",
       "<span style=white-space:pre-wrap>    x</span>\n",
       "}</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (formula, data, group = list(), lda = TRUE, ntree = 500, \n",
       "    sampsize = min(1e+05, nrow(data)), paral = FALSE, ncores = if (paral) max(detectCores() - \n",
       "        1, 1) else 1, ...) \n",
       "\\{\n",
       "    if (!inherits(formula, \"formula\")) \n",
       "        stop(\"abcrf.formula is only for formula objects\")\n",
       "    if (!inherits(data, \"data.frame\")) \n",
       "        stop(\"data needs to be a data.frame object\")\n",
       "    if (is.na(ncores)) \\{\n",
       "        warning(\"Unable to automatically detect the number of CPU cores, \\textbackslash{}n1 CPU core will be used or please specify ncores.\")\n",
       "        ncores <- 1\n",
       "    \\}\n",
       "    if ((!is.logical(paral)) \\textbar{}\\textbar{} (length(paral) != 1L)) \n",
       "        stop(\"paral should be TRUE or FALSE\")\n",
       "    if (!is.list(group)) \n",
       "        stop(\"group needs to be a list\")\n",
       "    mf <- match.call(expand.dots = FALSE)\n",
       "    m <- match(c(\"formula\", \"data\"), names(mf))\n",
       "    mf <- mf{[}c(1L, m){]}\n",
       "    mf{[}{[}1L{]}{]} <- as.name(\"model.frame\")\n",
       "    mf <- eval(mf, parent.frame())\n",
       "    if (!is.factor(model.response(mf))) \n",
       "        stop(\"response should be a factor containing the model indexes\")\n",
       "    if (nrow(data) == 0L \\textbar{}\\textbar{} is.null(nrow(data))) \n",
       "        stop(\"no simulation in the reference table (response, sumstat)\")\n",
       "    if ((!is.logical(lda)) \\&\\& (length(lda) != 1L)) \n",
       "        stop(\"lda should be TRUE or FALSE\")\n",
       "    if (length(group) != 0) \\{\n",
       "        ngroup <- length(group)\n",
       "        varn <- formula{[}{[}2{]}{]}\n",
       "        data{[}{[}as.character(varn){]}{]} <- as.vector(data{[}{[}as.character(varn){]}{]})\n",
       "        allmod <- unique(data{[}{[}as.character(varn){]}{]})\n",
       "        for (k in 1:ngroup) for (l in 1:length(group{[}{[}k{]}{]})) data{[}{[}as.character(varn){]}{]}{[}which(data{[}{[}as.character(varn){]}{]} == \n",
       "            group{[}{[}k{]}{]}{[}l{]}){]} <- paste(\"g\", k, sep = \"\")\n",
       "        if (!setequal(allmod, unlist(group))) \\{\n",
       "            diffe <- setdiff(allmod, unlist(group))\n",
       "            for (l in 1:length(diffe)) data <- data{[}-which(data{[}{[}as.character(varn){]}{]} == \n",
       "                diffe{[}l{]}), {]}\n",
       "        \\}\n",
       "        data{[}{[}as.character(varn){]}{]} <- as.factor(data{[}{[}as.character(varn){]}{]})\n",
       "    \\}\n",
       "    if (lda) \\{\n",
       "        model.lda <- lda(formula, data)\n",
       "        data <- cbind(data, as.matrix(predict(model.lda, data)\\$x))\n",
       "    \\}\n",
       "    else \\{\n",
       "        model.lda <- NULL\n",
       "    \\}\n",
       "    m <- names(match.call(expand.dots = TRUE))\n",
       "    if ((!\"sampsize\" \\%in\\% m) \\&\\& (nrow(data) <= 15)) \n",
       "        sampsize <- as.integer(sampsize/10)\n",
       "    if (sampsize > nrow(data)) \n",
       "        stop(\"sampsize too large\")\n",
       "    model.rf <- ranger(formula, data, num.trees = ntree, sample.fraction = sampsize/nrow(data), \n",
       "        num.threads = ncores, keep.inbag = TRUE, importance = \"impurity\", \n",
       "        ...)\n",
       "    class.error = vector()\n",
       "    for (i in 1:nrow(model.rf\\$confusion.matrix)) \\{\n",
       "        rowSum <- sum(model.rf\\$confusion.matrix{[}i, {]})\n",
       "        accurate <- diag(model.rf\\$confusion.matrix){[}i{]}\n",
       "        error <- rowSum - accurate\n",
       "        class.error{[}i{]} <- error/rowSum\n",
       "    \\}\n",
       "    model.rf\\$confusion.matrix <- cbind(model.rf\\$confusion.matrix, \n",
       "        class.error)\n",
       "    colnames(model.rf\\$confusion.matrix) <- c(paste(model.rf\\$forest\\$levels), \n",
       "        \"class.error\")\n",
       "    model.rf\\$model.rf\n",
       "    cl <- match.call()\n",
       "    cl{[}{[}1{]}{]} <- as.name(\"abcrf\")\n",
       "    x <- list(call = cl, lda = lda, formula = formula, group = group, \n",
       "        model.rf = model.rf, model.lda = model.lda, prior.err = model.rf\\$prediction.error)\n",
       "    class(x) <- \"abcrf\"\n",
       "    x\n",
       "\\}\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (formula, data, group = list(), lda = TRUE, ntree = 500, \n",
       "    sampsize = min(1e+05, nrow(data)), paral = FALSE, ncores = if (paral) max(detectCores() - \n",
       "        1, 1) else 1, ...) \n",
       "{\n",
       "    if (!inherits(formula, \"formula\")) \n",
       "        stop(\"abcrf.formula is only for formula objects\")\n",
       "    if (!inherits(data, \"data.frame\")) \n",
       "        stop(\"data needs to be a data.frame object\")\n",
       "    if (is.na(ncores)) {\n",
       "        warning(\"Unable to automatically detect the number of CPU cores, \\n1 CPU core will be used or please specify ncores.\")\n",
       "        ncores <- 1\n",
       "    }\n",
       "    if ((!is.logical(paral)) || (length(paral) != 1L)) \n",
       "        stop(\"paral should be TRUE or FALSE\")\n",
       "    if (!is.list(group)) \n",
       "        stop(\"group needs to be a list\")\n",
       "    mf <- match.call(expand.dots = FALSE)\n",
       "    m <- match(c(\"formula\", \"data\"), names(mf))\n",
       "    mf <- mf[c(1L, m)]\n",
       "    mf[[1L]] <- as.name(\"model.frame\")\n",
       "    mf <- eval(mf, parent.frame())\n",
       "    if (!is.factor(model.response(mf))) \n",
       "        stop(\"response should be a factor containing the model indexes\")\n",
       "    if (nrow(data) == 0L || is.null(nrow(data))) \n",
       "        stop(\"no simulation in the reference table (response, sumstat)\")\n",
       "    if ((!is.logical(lda)) && (length(lda) != 1L)) \n",
       "        stop(\"lda should be TRUE or FALSE\")\n",
       "    if (length(group) != 0) {\n",
       "        ngroup <- length(group)\n",
       "        varn <- formula[[2]]\n",
       "        data[[as.character(varn)]] <- as.vector(data[[as.character(varn)]])\n",
       "        allmod <- unique(data[[as.character(varn)]])\n",
       "        for (k in 1:ngroup) for (l in 1:length(group[[k]])) data[[as.character(varn)]][which(data[[as.character(varn)]] == \n",
       "            group[[k]][l])] <- paste(\"g\", k, sep = \"\")\n",
       "        if (!setequal(allmod, unlist(group))) {\n",
       "            diffe <- setdiff(allmod, unlist(group))\n",
       "            for (l in 1:length(diffe)) data <- data[-which(data[[as.character(varn)]] == \n",
       "                diffe[l]), ]\n",
       "        }\n",
       "        data[[as.character(varn)]] <- as.factor(data[[as.character(varn)]])\n",
       "    }\n",
       "    if (lda) {\n",
       "        model.lda <- lda(formula, data)\n",
       "        data <- cbind(data, as.matrix(predict(model.lda, data)$x))\n",
       "    }\n",
       "    else {\n",
       "        model.lda <- NULL\n",
       "    }\n",
       "    m <- names(match.call(expand.dots = TRUE))\n",
       "    if ((!\"sampsize\" %in% m) && (nrow(data) <= 15)) \n",
       "        sampsize <- as.integer(sampsize/10)\n",
       "    if (sampsize > nrow(data)) \n",
       "        stop(\"sampsize too large\")\n",
       "    model.rf <- ranger(formula, data, num.trees = ntree, sample.fraction = sampsize/nrow(data), \n",
       "        num.threads = ncores, keep.inbag = TRUE, importance = \"impurity\", \n",
       "        ...)\n",
       "    class.error = vector()\n",
       "    for (i in 1:nrow(model.rf$confusion.matrix)) {\n",
       "        rowSum <- sum(model.rf$confusion.matrix[i, ])\n",
       "        accurate <- diag(model.rf$confusion.matrix)[i]\n",
       "        error <- rowSum - accurate\n",
       "        class.error[i] <- error/rowSum\n",
       "    }\n",
       "    model.rf$confusion.matrix <- cbind(model.rf$confusion.matrix, \n",
       "        class.error)\n",
       "    colnames(model.rf$confusion.matrix) <- c(paste(model.rf$forest$levels), \n",
       "        \"class.error\")\n",
       "    model.rf$model.rf\n",
       "    cl <- match.call()\n",
       "    cl[[1]] <- as.name(\"abcrf\")\n",
       "    x <- list(call = cl, lda = lda, formula = formula, group = group, \n",
       "        model.rf = model.rf, model.lda = model.lda, prior.err = model.rf$prediction.error)\n",
       "    class(x) <- \"abcrf\"\n",
       "    x\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "function (formula, data, group = list(), lda = TRUE, ntree = 500, \n",
       "    sampsize = min(1e+05, nrow(data)), paral = FALSE, ncores = if (paral) max(detectCores() - \n",
       "        1, 1) else 1, ...) \n",
       "{\n",
       "    if (!inherits(formula, \"formula\")) \n",
       "        stop(\"abcrf.formula is only for formula objects\")\n",
       "    if (!inherits(data, \"data.frame\")) \n",
       "        stop(\"data needs to be a data.frame object\")\n",
       "    if (is.na(ncores)) {\n",
       "        warning(\"Unable to automatically detect the number of CPU cores, \\n1 CPU core will be used or please specify ncores.\")\n",
       "        ncores <- 1\n",
       "    }\n",
       "    if ((!is.logical(paral)) || (length(paral) != 1L)) \n",
       "        stop(\"paral should be TRUE or FALSE\")\n",
       "    if (!is.list(group)) \n",
       "        stop(\"group needs to be a list\")\n",
       "    mf <- match.call(expand.dots = FALSE)\n",
       "    m <- match(c(\"formula\", \"data\"), names(mf))\n",
       "    mf <- mf[c(1L, m)]\n",
       "    mf[[1L]] <- as.name(\"model.frame\")\n",
       "    mf <- eval(mf, parent.frame())\n",
       "    if (!is.factor(model.response(mf))) \n",
       "        stop(\"response should be a factor containing the model indexes\")\n",
       "    if (nrow(data) == 0L || is.null(nrow(data))) \n",
       "        stop(\"no simulation in the reference table (response, sumstat)\")\n",
       "    if ((!is.logical(lda)) && (length(lda) != 1L)) \n",
       "        stop(\"lda should be TRUE or FALSE\")\n",
       "    if (length(group) != 0) {\n",
       "        ngroup <- length(group)\n",
       "        varn <- formula[[2]]\n",
       "        data[[as.character(varn)]] <- as.vector(data[[as.character(varn)]])\n",
       "        allmod <- unique(data[[as.character(varn)]])\n",
       "        for (k in 1:ngroup) for (l in 1:length(group[[k]])) data[[as.character(varn)]][which(data[[as.character(varn)]] == \n",
       "            group[[k]][l])] <- paste(\"g\", k, sep = \"\")\n",
       "        if (!setequal(allmod, unlist(group))) {\n",
       "            diffe <- setdiff(allmod, unlist(group))\n",
       "            for (l in 1:length(diffe)) data <- data[-which(data[[as.character(varn)]] == \n",
       "                diffe[l]), ]\n",
       "        }\n",
       "        data[[as.character(varn)]] <- as.factor(data[[as.character(varn)]])\n",
       "    }\n",
       "    if (lda) {\n",
       "        model.lda <- lda(formula, data)\n",
       "        data <- cbind(data, as.matrix(predict(model.lda, data)$x))\n",
       "    }\n",
       "    else {\n",
       "        model.lda <- NULL\n",
       "    }\n",
       "    m <- names(match.call(expand.dots = TRUE))\n",
       "    if ((!\"sampsize\" %in% m) && (nrow(data) <= 15)) \n",
       "        sampsize <- as.integer(sampsize/10)\n",
       "    if (sampsize > nrow(data)) \n",
       "        stop(\"sampsize too large\")\n",
       "    model.rf <- ranger(formula, data, num.trees = ntree, sample.fraction = sampsize/nrow(data), \n",
       "        num.threads = ncores, keep.inbag = TRUE, importance = \"impurity\", \n",
       "        ...)\n",
       "    class.error = vector()\n",
       "    for (i in 1:nrow(model.rf$confusion.matrix)) {\n",
       "        rowSum <- sum(model.rf$confusion.matrix[i, ])\n",
       "        accurate <- diag(model.rf$confusion.matrix)[i]\n",
       "        error <- rowSum - accurate\n",
       "        class.error[i] <- error/rowSum\n",
       "    }\n",
       "    model.rf$confusion.matrix <- cbind(model.rf$confusion.matrix, \n",
       "        class.error)\n",
       "    colnames(model.rf$confusion.matrix) <- c(paste(model.rf$forest$levels), \n",
       "        \"class.error\")\n",
       "    model.rf$model.rf\n",
       "    cl <- match.call()\n",
       "    cl[[1]] <- as.name(\"abcrf\")\n",
       "    x <- list(call = cl, lda = lda, formula = formula, group = group, \n",
       "        model.rf = model.rf, model.lda = model.lda, prior.err = model.rf$prediction.error)\n",
       "    class(x) <- \"abcrf\"\n",
       "    x\n",
       "}\n",
       "<bytecode: 0x7fea2544f0b8>\n",
       "<environment: namespace:abcrf>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abcrf:::abcrf.formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ranger\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ranger result\n",
       "\n",
       "Call:\n",
       " ranger(Species ~ ., data = iris) \n",
       "\n",
       "Type:                             Classification \n",
       "Number of trees:                  500 \n",
       "Sample size:                      150 \n",
       "Number of independent variables:  4 \n",
       "Mtry:                             2 \n",
       "Target node size:                 1 \n",
       "Variable importance mode:         none \n",
       "Splitrule:                        gini \n",
       "OOB prediction error:             4.67 % "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(ranger)\n",
    "\n",
    "## Classification forest with default settings\n",
    "ranger(Species ~ ., data = iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            \n",
       "             setosa versicolor virginica\n",
       "  setosa         17          0         0\n",
       "  versicolor      0         15         0\n",
       "  virginica       0          2        16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Prediction\n",
    "train.idx <- sample(nrow(iris), 2/3 * nrow(iris))\n",
    "iris.train <- iris[train.idx, ]\n",
    "iris.test <- iris[-train.idx, ]\n",
    "rg.iris <- ranger(Species ~ ., data = iris.train)\n",
    "pred.iris <- predict(rg.iris, data = iris.test)\n",
    "table(iris.test$Species, pred.iris$predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>quantile= 0.1</th><th scope=col>quantile= 0.5</th><th scope=col>quantile= 0.9</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>21.0 </td><td>24.40</td><td>32.55</td></tr>\n",
       "\t<tr><td>21.0 </td><td>22.80</td><td>32.40</td></tr>\n",
       "\t<tr><td>13.3 </td><td>15.95</td><td>30.40</td></tr>\n",
       "\t<tr><td>15.2 </td><td>21.00</td><td>22.80</td></tr>\n",
       "\t<tr><td>13.3 </td><td>14.30</td><td>19.20</td></tr>\n",
       "\t<tr><td>21.0 </td><td>22.80</td><td>32.40</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " quantile= 0.1 & quantile= 0.5 & quantile= 0.9\\\\\n",
       "\\hline\n",
       "\t 21.0  & 24.40 & 32.55\\\\\n",
       "\t 21.0  & 22.80 & 32.40\\\\\n",
       "\t 13.3  & 15.95 & 30.40\\\\\n",
       "\t 15.2  & 21.00 & 22.80\\\\\n",
       "\t 13.3  & 14.30 & 19.20\\\\\n",
       "\t 21.0  & 22.80 & 32.40\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| quantile= 0.1 | quantile= 0.5 | quantile= 0.9 |\n",
       "|---|---|---|\n",
       "| 21.0  | 24.40 | 32.55 |\n",
       "| 21.0  | 22.80 | 32.40 |\n",
       "| 13.3  | 15.95 | 30.40 |\n",
       "| 15.2  | 21.00 | 22.80 |\n",
       "| 13.3  | 14.30 | 19.20 |\n",
       "| 21.0  | 22.80 | 32.40 |\n",
       "\n"
      ],
      "text/plain": [
       "     quantile= 0.1 quantile= 0.5 quantile= 0.9\n",
       "[1,] 21.0          24.40         32.55        \n",
       "[2,] 21.0          22.80         32.40        \n",
       "[3,] 13.3          15.95         30.40        \n",
       "[4,] 15.2          21.00         22.80        \n",
       "[5,] 13.3          14.30         19.20        \n",
       "[6,] 21.0          22.80         32.40        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Quantile regression forest\n",
    "rf <- ranger(mpg ~ ., mtcars[1:26, ], quantreg = TRUE)\n",
    "pred <- predict(rf, mtcars[27:32, ], type = \"quantiles\")\n",
    "pred$predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Sepal.Length</dt>\n",
       "\t\t<dd>9.97805768983597</dd>\n",
       "\t<dt>Sepal.Width</dt>\n",
       "\t\t<dd>2.54536927074438</dd>\n",
       "\t<dt>Petal.Length</dt>\n",
       "\t\t<dd>42.9250358317397</dd>\n",
       "\t<dt>Petal.Width</dt>\n",
       "\t\t<dd>43.8062038743466</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Sepal.Length] 9.97805768983597\n",
       "\\item[Sepal.Width] 2.54536927074438\n",
       "\\item[Petal.Length] 42.9250358317397\n",
       "\\item[Petal.Width] 43.8062038743466\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Sepal.Length\n",
       ":   9.97805768983597Sepal.Width\n",
       ":   2.54536927074438Petal.Length\n",
       ":   42.9250358317397Petal.Width\n",
       ":   43.8062038743466\n",
       "\n"
      ],
      "text/plain": [
       "Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n",
       "    9.978058     2.545369    42.925036    43.806204 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Variable importance\n",
    "rg.iris <- ranger(Species ~ ., data = iris, importance = \"impurity\")\n",
    "rg.iris$variable.importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: survival\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAIAAAByhViMAAAABmJLR0QA/wD/AP+gvaeTAAAg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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Survival forest\n",
    "require(survival)\n",
    "rg.veteran <- ranger(Surv(time, status) ~ ., data = veteran)\n",
    "plot(rg.veteran$unique.death.times, rg.veteran$survival[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ranger result\n",
       "\n",
       "Call:\n",
       " ranger(dependent.variable.name = \"Species\", data = iris) \n",
       "\n",
       "Type:                             Classification \n",
       "Number of trees:                  500 \n",
       "Sample size:                      150 \n",
       "Number of independent variables:  4 \n",
       "Mtry:                             2 \n",
       "Target node size:                 1 \n",
       "Variable importance mode:         none \n",
       "Splitrule:                        gini \n",
       "OOB prediction error:             4.00 % "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Alternative interface\n",
    "ranger(dependent.variable.name = \"Species\", data = iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Not run: \n",
    "# ## Use GenABEL interface to read Plink data into R and grow a classification forest\n",
    "# ## The ped and map files are not included\n",
    "# library(GenABEL)\n",
    "# convert.snp.ped(\"data.ped\", \"data.map\", \"data.raw\")\n",
    "# dat.gwaa <- load.gwaa.data(\"data.pheno\", \"data.raw\")\n",
    "# phdata(dat.gwaa)$trait <- factor(phdata(dat.gwaa)$trait)\n",
    "# ranger(trait ~ ., data = dat.gwaa)\n",
    "\n",
    "# ## End(Not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>$names</strong> = <ol class=list-inline>\n",
       "\t<li>'modindex'</li>\n",
       "\t<li>'param'</li>\n",
       "\t<li>'sumsta'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\textbf{\\$names} = \\begin{enumerate*}\n",
       "\\item 'modindex'\n",
       "\\item 'param'\n",
       "\\item 'sumsta'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "**$names** = 1. 'modindex'\n",
       "2. 'param'\n",
       "3. 'sumsta'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$names\n",
       "[1] \"modindex\" \"param\"    \"sumsta\"  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attributes(snp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(snp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(abcrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ranger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2929.0962</td><td>2929.0959</td><td>2929.0954</td><td>2929.0944</td><td>2929.0933</td><td>2929.0922</td><td>2929.0912</td><td>2929.0903</td><td>2929.0897</td><td>2929.0894</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1658.5402</td><td>1658.7067</td><td>1658.7571</td><td>1658.6872</td><td>1658.6285</td><td>1658.5365</td><td>1658.3883</td><td>1658.2525</td><td>1658.0376</td><td>1657.7735</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1279.5455</td><td>1279.5628</td><td>1279.5824</td><td>1279.6045</td><td>1279.6441</td><td>1279.6889</td><td>1279.7433</td><td>1279.7489</td><td>1279.6423</td><td>1279.4628</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1253.8039</td><td>1253.7999</td><td>1253.8067</td><td>1253.8248</td><td>1253.8372</td><td>1253.8593</td><td>1253.9103</td><td>1253.9264</td><td>1253.8883</td><td>1253.8126</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1233.9172</td><td>1233.9277</td><td>1233.9347</td><td>1233.9379</td><td>1233.9383</td><td>1233.9406</td><td>1233.9538</td><td>1233.9667</td><td>1233.9699</td><td>1233.9660</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1202.3669</td><td>1202.3763</td><td>1202.3799</td><td>1202.3773</td><td>1202.3802</td><td>1202.3816</td><td>1202.3807</td><td>1202.3927</td><td>1202.4127</td><td>1202.4369</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1165.8423</td><td>1165.8446</td><td>1165.8447</td><td>1165.8424</td><td>1165.8469</td><td>1165.8497</td><td>1165.8472</td><td>1165.8569</td><td>1165.8761</td><td>1165.9002</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1130.7162</td><td>1130.7148</td><td>1130.7136</td><td>1130.7128</td><td>1130.7168</td><td>1130.7195</td><td>1130.7181</td><td>1130.7253</td><td>1130.7381</td><td>1130.7533</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1098.2779</td><td>1098.2764</td><td>1098.2756</td><td>1098.2756</td><td>1098.2787</td><td>1098.2806</td><td>1098.2801</td><td>1098.2860</td><td>1098.2932</td><td>1098.3005</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1068.6779</td><td>1068.6777</td><td>1068.6776</td><td>1068.6777</td><td>1068.6802</td><td>1068.6815</td><td>1068.6811</td><td>1068.6864</td><td>1068.6902</td><td>1068.6928</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1041.6786</td><td>1041.6797</td><td>1041.6802</td><td>1041.6801</td><td>1041.6821</td><td>1041.6831</td><td>1041.6824</td><td>1041.6874</td><td>1041.6893</td><td>1041.6893</td><td>TRUE     </td></tr>\n",
       "\t<tr><td>1017.0699</td><td>1017.0718</td><td>1017.0726</td><td>1017.0723</td><td>1017.0741</td><td>1017.0747</td><td>1017.0737</td><td>1017.0784</td><td>1017.0791</td><td>1017.0776</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 994.6932</td><td> 994.6956</td><td> 994.6966</td><td> 994.6961</td><td> 994.6977</td><td> 994.6981</td><td> 994.6969</td><td> 994.7012</td><td> 994.7011</td><td> 994.6983</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 974.4405</td><td> 974.4432</td><td> 974.4442</td><td> 974.4436</td><td> 974.4450</td><td> 974.4453</td><td> 974.4438</td><td> 974.4479</td><td> 974.4469</td><td> 974.4430</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 956.2296</td><td> 956.2326</td><td> 956.2337</td><td> 956.2330</td><td> 956.2343</td><td> 956.2343</td><td> 956.2328</td><td> 956.2365</td><td> 956.2348</td><td> 956.2299</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 939.9871</td><td> 939.9902</td><td> 939.9914</td><td> 939.9906</td><td> 939.9918</td><td> 939.9917</td><td> 939.9901</td><td> 939.9936</td><td> 939.9912</td><td> 939.9854</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 925.6381</td><td> 925.6415</td><td> 925.6427</td><td> 925.6418</td><td> 925.6429</td><td> 925.6427</td><td> 925.6410</td><td> 925.6442</td><td> 925.6412</td><td> 925.6347</td><td>TRUE     </td></tr>\n",
       "\t<tr><td> 913.1045</td><td> 913.1082</td><td> 913.1095</td><td> 913.1085</td><td> 913.1095</td><td> 913.1092</td><td> 913.1074</td><td> 913.1104</td><td> 913.1069</td><td> 913.0996</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 902.3059</td><td> 902.3097</td><td> 902.3111</td><td> 902.3100</td><td> 902.3110</td><td> 902.3107</td><td> 902.3088</td><td> 902.3115</td><td> 902.3075</td><td> 902.2996</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 893.1608</td><td> 893.1648</td><td> 893.1663</td><td> 893.1651</td><td> 893.1660</td><td> 893.1657</td><td> 893.1637</td><td> 893.1663</td><td> 893.1618</td><td> 893.1532</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 885.5886</td><td> 885.5928</td><td> 885.5944</td><td> 885.5931</td><td> 885.5940</td><td> 885.5936</td><td> 885.5916</td><td> 885.5939</td><td> 885.5890</td><td> 885.5799</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 879.5102</td><td> 879.5147</td><td> 879.5163</td><td> 879.5150</td><td> 879.5158</td><td> 879.5154</td><td> 879.5134</td><td> 879.5155</td><td> 879.5102</td><td> 879.5005</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 874.8489</td><td> 874.8536</td><td> 874.8552</td><td> 874.8538</td><td> 874.8547</td><td> 874.8542</td><td> 874.8521</td><td> 874.8541</td><td> 874.8485</td><td> 874.8383</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 871.5300</td><td> 871.5349</td><td> 871.5366</td><td> 871.5352</td><td> 871.5360</td><td> 871.5356</td><td> 871.5334</td><td> 871.5352</td><td> 871.5292</td><td> 871.5185</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 869.4816</td><td> 869.4867</td><td> 869.4885</td><td> 869.4870</td><td> 869.4878</td><td> 869.4874</td><td> 869.4852</td><td> 869.4869</td><td> 869.4805</td><td> 869.4693</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 868.6342</td><td> 868.6395</td><td> 868.6414</td><td> 868.6398</td><td> 868.6407</td><td> 868.6402</td><td> 868.6380</td><td> 868.6395</td><td> 868.6328</td><td> 868.6211</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 868.9208</td><td> 868.9263</td><td> 868.9283</td><td> 868.9267</td><td> 868.9276</td><td> 868.9271</td><td> 868.9249</td><td> 868.9262</td><td> 868.9192</td><td> 868.9070</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 870.2772</td><td> 870.2829</td><td> 870.2850</td><td> 870.2833</td><td> 870.2842</td><td> 870.2837</td><td> 870.2814</td><td> 870.2827</td><td> 870.2753</td><td> 870.2627</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 872.6414</td><td> 872.6473</td><td> 872.6495</td><td> 872.6478</td><td> 872.6487</td><td> 872.6481</td><td> 872.6459</td><td> 872.6470</td><td> 872.6393</td><td> 872.6262</td><td>FALSE    </td></tr>\n",
       "\t<tr><td> 875.9541</td><td> 875.9603</td><td> 875.9626</td><td> 875.9608</td><td> 875.9617</td><td> 875.9612</td><td> 875.9589</td><td> 875.9599</td><td> 875.9519</td><td> 875.9384</td><td>FALSE    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & Y\\\\\n",
       "\\hline\n",
       "\t 2929.0962 & 2929.0959 & 2929.0954 & 2929.0944 & 2929.0933 & 2929.0922 & 2929.0912 & 2929.0903 & 2929.0897 & 2929.0894 & TRUE     \\\\\n",
       "\t 1658.5402 & 1658.7067 & 1658.7571 & 1658.6872 & 1658.6285 & 1658.5365 & 1658.3883 & 1658.2525 & 1658.0376 & 1657.7735 & TRUE     \\\\\n",
       "\t 1279.5455 & 1279.5628 & 1279.5824 & 1279.6045 & 1279.6441 & 1279.6889 & 1279.7433 & 1279.7489 & 1279.6423 & 1279.4628 & TRUE     \\\\\n",
       "\t 1253.8039 & 1253.7999 & 1253.8067 & 1253.8248 & 1253.8372 & 1253.8593 & 1253.9103 & 1253.9264 & 1253.8883 & 1253.8126 & TRUE     \\\\\n",
       "\t 1233.9172 & 1233.9277 & 1233.9347 & 1233.9379 & 1233.9383 & 1233.9406 & 1233.9538 & 1233.9667 & 1233.9699 & 1233.9660 & TRUE     \\\\\n",
       "\t 1202.3669 & 1202.3763 & 1202.3799 & 1202.3773 & 1202.3802 & 1202.3816 & 1202.3807 & 1202.3927 & 1202.4127 & 1202.4369 & TRUE     \\\\\n",
       "\t 1165.8423 & 1165.8446 & 1165.8447 & 1165.8424 & 1165.8469 & 1165.8497 & 1165.8472 & 1165.8569 & 1165.8761 & 1165.9002 & TRUE     \\\\\n",
       "\t 1130.7162 & 1130.7148 & 1130.7136 & 1130.7128 & 1130.7168 & 1130.7195 & 1130.7181 & 1130.7253 & 1130.7381 & 1130.7533 & TRUE     \\\\\n",
       "\t 1098.2779 & 1098.2764 & 1098.2756 & 1098.2756 & 1098.2787 & 1098.2806 & 1098.2801 & 1098.2860 & 1098.2932 & 1098.3005 & TRUE     \\\\\n",
       "\t 1068.6779 & 1068.6777 & 1068.6776 & 1068.6777 & 1068.6802 & 1068.6815 & 1068.6811 & 1068.6864 & 1068.6902 & 1068.6928 & TRUE     \\\\\n",
       "\t 1041.6786 & 1041.6797 & 1041.6802 & 1041.6801 & 1041.6821 & 1041.6831 & 1041.6824 & 1041.6874 & 1041.6893 & 1041.6893 & TRUE     \\\\\n",
       "\t 1017.0699 & 1017.0718 & 1017.0726 & 1017.0723 & 1017.0741 & 1017.0747 & 1017.0737 & 1017.0784 & 1017.0791 & 1017.0776 & TRUE     \\\\\n",
       "\t  994.6932 &  994.6956 &  994.6966 &  994.6961 &  994.6977 &  994.6981 &  994.6969 &  994.7012 &  994.7011 &  994.6983 & TRUE     \\\\\n",
       "\t  974.4405 &  974.4432 &  974.4442 &  974.4436 &  974.4450 &  974.4453 &  974.4438 &  974.4479 &  974.4469 &  974.4430 & TRUE     \\\\\n",
       "\t  956.2296 &  956.2326 &  956.2337 &  956.2330 &  956.2343 &  956.2343 &  956.2328 &  956.2365 &  956.2348 &  956.2299 & TRUE     \\\\\n",
       "\t  939.9871 &  939.9902 &  939.9914 &  939.9906 &  939.9918 &  939.9917 &  939.9901 &  939.9936 &  939.9912 &  939.9854 & TRUE     \\\\\n",
       "\t  925.6381 &  925.6415 &  925.6427 &  925.6418 &  925.6429 &  925.6427 &  925.6410 &  925.6442 &  925.6412 &  925.6347 & TRUE     \\\\\n",
       "\t  913.1045 &  913.1082 &  913.1095 &  913.1085 &  913.1095 &  913.1092 &  913.1074 &  913.1104 &  913.1069 &  913.0996 & FALSE    \\\\\n",
       "\t  902.3059 &  902.3097 &  902.3111 &  902.3100 &  902.3110 &  902.3107 &  902.3088 &  902.3115 &  902.3075 &  902.2996 & FALSE    \\\\\n",
       "\t  893.1608 &  893.1648 &  893.1663 &  893.1651 &  893.1660 &  893.1657 &  893.1637 &  893.1663 &  893.1618 &  893.1532 & FALSE    \\\\\n",
       "\t  885.5886 &  885.5928 &  885.5944 &  885.5931 &  885.5940 &  885.5936 &  885.5916 &  885.5939 &  885.5890 &  885.5799 & FALSE    \\\\\n",
       "\t  879.5102 &  879.5147 &  879.5163 &  879.5150 &  879.5158 &  879.5154 &  879.5134 &  879.5155 &  879.5102 &  879.5005 & FALSE    \\\\\n",
       "\t  874.8489 &  874.8536 &  874.8552 &  874.8538 &  874.8547 &  874.8542 &  874.8521 &  874.8541 &  874.8485 &  874.8383 & FALSE    \\\\\n",
       "\t  871.5300 &  871.5349 &  871.5366 &  871.5352 &  871.5360 &  871.5356 &  871.5334 &  871.5352 &  871.5292 &  871.5185 & FALSE    \\\\\n",
       "\t  869.4816 &  869.4867 &  869.4885 &  869.4870 &  869.4878 &  869.4874 &  869.4852 &  869.4869 &  869.4805 &  869.4693 & FALSE    \\\\\n",
       "\t  868.6342 &  868.6395 &  868.6414 &  868.6398 &  868.6407 &  868.6402 &  868.6380 &  868.6395 &  868.6328 &  868.6211 & FALSE    \\\\\n",
       "\t  868.9208 &  868.9263 &  868.9283 &  868.9267 &  868.9276 &  868.9271 &  868.9249 &  868.9262 &  868.9192 &  868.9070 & FALSE    \\\\\n",
       "\t  870.2772 &  870.2829 &  870.2850 &  870.2833 &  870.2842 &  870.2837 &  870.2814 &  870.2827 &  870.2753 &  870.2627 & FALSE    \\\\\n",
       "\t  872.6414 &  872.6473 &  872.6495 &  872.6478 &  872.6487 &  872.6481 &  872.6459 &  872.6470 &  872.6393 &  872.6262 & FALSE    \\\\\n",
       "\t  875.9541 &  875.9603 &  875.9626 &  875.9608 &  875.9617 &  875.9612 &  875.9589 &  875.9599 &  875.9519 &  875.9384 & FALSE    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | Y |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2929.0962 | 2929.0959 | 2929.0954 | 2929.0944 | 2929.0933 | 2929.0922 | 2929.0912 | 2929.0903 | 2929.0897 | 2929.0894 | TRUE      |\n",
       "| 1658.5402 | 1658.7067 | 1658.7571 | 1658.6872 | 1658.6285 | 1658.5365 | 1658.3883 | 1658.2525 | 1658.0376 | 1657.7735 | TRUE      |\n",
       "| 1279.5455 | 1279.5628 | 1279.5824 | 1279.6045 | 1279.6441 | 1279.6889 | 1279.7433 | 1279.7489 | 1279.6423 | 1279.4628 | TRUE      |\n",
       "| 1253.8039 | 1253.7999 | 1253.8067 | 1253.8248 | 1253.8372 | 1253.8593 | 1253.9103 | 1253.9264 | 1253.8883 | 1253.8126 | TRUE      |\n",
       "| 1233.9172 | 1233.9277 | 1233.9347 | 1233.9379 | 1233.9383 | 1233.9406 | 1233.9538 | 1233.9667 | 1233.9699 | 1233.9660 | TRUE      |\n",
       "| 1202.3669 | 1202.3763 | 1202.3799 | 1202.3773 | 1202.3802 | 1202.3816 | 1202.3807 | 1202.3927 | 1202.4127 | 1202.4369 | TRUE      |\n",
       "| 1165.8423 | 1165.8446 | 1165.8447 | 1165.8424 | 1165.8469 | 1165.8497 | 1165.8472 | 1165.8569 | 1165.8761 | 1165.9002 | TRUE      |\n",
       "| 1130.7162 | 1130.7148 | 1130.7136 | 1130.7128 | 1130.7168 | 1130.7195 | 1130.7181 | 1130.7253 | 1130.7381 | 1130.7533 | TRUE      |\n",
       "| 1098.2779 | 1098.2764 | 1098.2756 | 1098.2756 | 1098.2787 | 1098.2806 | 1098.2801 | 1098.2860 | 1098.2932 | 1098.3005 | TRUE      |\n",
       "| 1068.6779 | 1068.6777 | 1068.6776 | 1068.6777 | 1068.6802 | 1068.6815 | 1068.6811 | 1068.6864 | 1068.6902 | 1068.6928 | TRUE      |\n",
       "| 1041.6786 | 1041.6797 | 1041.6802 | 1041.6801 | 1041.6821 | 1041.6831 | 1041.6824 | 1041.6874 | 1041.6893 | 1041.6893 | TRUE      |\n",
       "| 1017.0699 | 1017.0718 | 1017.0726 | 1017.0723 | 1017.0741 | 1017.0747 | 1017.0737 | 1017.0784 | 1017.0791 | 1017.0776 | TRUE      |\n",
       "|  994.6932 |  994.6956 |  994.6966 |  994.6961 |  994.6977 |  994.6981 |  994.6969 |  994.7012 |  994.7011 |  994.6983 | TRUE      |\n",
       "|  974.4405 |  974.4432 |  974.4442 |  974.4436 |  974.4450 |  974.4453 |  974.4438 |  974.4479 |  974.4469 |  974.4430 | TRUE      |\n",
       "|  956.2296 |  956.2326 |  956.2337 |  956.2330 |  956.2343 |  956.2343 |  956.2328 |  956.2365 |  956.2348 |  956.2299 | TRUE      |\n",
       "|  939.9871 |  939.9902 |  939.9914 |  939.9906 |  939.9918 |  939.9917 |  939.9901 |  939.9936 |  939.9912 |  939.9854 | TRUE      |\n",
       "|  925.6381 |  925.6415 |  925.6427 |  925.6418 |  925.6429 |  925.6427 |  925.6410 |  925.6442 |  925.6412 |  925.6347 | TRUE      |\n",
       "|  913.1045 |  913.1082 |  913.1095 |  913.1085 |  913.1095 |  913.1092 |  913.1074 |  913.1104 |  913.1069 |  913.0996 | FALSE     |\n",
       "|  902.3059 |  902.3097 |  902.3111 |  902.3100 |  902.3110 |  902.3107 |  902.3088 |  902.3115 |  902.3075 |  902.2996 | FALSE     |\n",
       "|  893.1608 |  893.1648 |  893.1663 |  893.1651 |  893.1660 |  893.1657 |  893.1637 |  893.1663 |  893.1618 |  893.1532 | FALSE     |\n",
       "|  885.5886 |  885.5928 |  885.5944 |  885.5931 |  885.5940 |  885.5936 |  885.5916 |  885.5939 |  885.5890 |  885.5799 | FALSE     |\n",
       "|  879.5102 |  879.5147 |  879.5163 |  879.5150 |  879.5158 |  879.5154 |  879.5134 |  879.5155 |  879.5102 |  879.5005 | FALSE     |\n",
       "|  874.8489 |  874.8536 |  874.8552 |  874.8538 |  874.8547 |  874.8542 |  874.8521 |  874.8541 |  874.8485 |  874.8383 | FALSE     |\n",
       "|  871.5300 |  871.5349 |  871.5366 |  871.5352 |  871.5360 |  871.5356 |  871.5334 |  871.5352 |  871.5292 |  871.5185 | FALSE     |\n",
       "|  869.4816 |  869.4867 |  869.4885 |  869.4870 |  869.4878 |  869.4874 |  869.4852 |  869.4869 |  869.4805 |  869.4693 | FALSE     |\n",
       "|  868.6342 |  868.6395 |  868.6414 |  868.6398 |  868.6407 |  868.6402 |  868.6380 |  868.6395 |  868.6328 |  868.6211 | FALSE     |\n",
       "|  868.9208 |  868.9263 |  868.9283 |  868.9267 |  868.9276 |  868.9271 |  868.9249 |  868.9262 |  868.9192 |  868.9070 | FALSE     |\n",
       "|  870.2772 |  870.2829 |  870.2850 |  870.2833 |  870.2842 |  870.2837 |  870.2814 |  870.2827 |  870.2753 |  870.2627 | FALSE     |\n",
       "|  872.6414 |  872.6473 |  872.6495 |  872.6478 |  872.6487 |  872.6481 |  872.6459 |  872.6470 |  872.6393 |  872.6262 | FALSE     |\n",
       "|  875.9541 |  875.9603 |  875.9626 |  875.9608 |  875.9617 |  875.9612 |  875.9589 |  875.9599 |  875.9519 |  875.9384 | FALSE     |\n",
       "\n"
      ],
      "text/plain": [
       "   V1        V2        V3        V4        V5        V6        V7       \n",
       "1  2929.0962 2929.0959 2929.0954 2929.0944 2929.0933 2929.0922 2929.0912\n",
       "2  1658.5402 1658.7067 1658.7571 1658.6872 1658.6285 1658.5365 1658.3883\n",
       "3  1279.5455 1279.5628 1279.5824 1279.6045 1279.6441 1279.6889 1279.7433\n",
       "4  1253.8039 1253.7999 1253.8067 1253.8248 1253.8372 1253.8593 1253.9103\n",
       "5  1233.9172 1233.9277 1233.9347 1233.9379 1233.9383 1233.9406 1233.9538\n",
       "6  1202.3669 1202.3763 1202.3799 1202.3773 1202.3802 1202.3816 1202.3807\n",
       "7  1165.8423 1165.8446 1165.8447 1165.8424 1165.8469 1165.8497 1165.8472\n",
       "8  1130.7162 1130.7148 1130.7136 1130.7128 1130.7168 1130.7195 1130.7181\n",
       "9  1098.2779 1098.2764 1098.2756 1098.2756 1098.2787 1098.2806 1098.2801\n",
       "10 1068.6779 1068.6777 1068.6776 1068.6777 1068.6802 1068.6815 1068.6811\n",
       "11 1041.6786 1041.6797 1041.6802 1041.6801 1041.6821 1041.6831 1041.6824\n",
       "12 1017.0699 1017.0718 1017.0726 1017.0723 1017.0741 1017.0747 1017.0737\n",
       "13  994.6932  994.6956  994.6966  994.6961  994.6977  994.6981  994.6969\n",
       "14  974.4405  974.4432  974.4442  974.4436  974.4450  974.4453  974.4438\n",
       "15  956.2296  956.2326  956.2337  956.2330  956.2343  956.2343  956.2328\n",
       "16  939.9871  939.9902  939.9914  939.9906  939.9918  939.9917  939.9901\n",
       "17  925.6381  925.6415  925.6427  925.6418  925.6429  925.6427  925.6410\n",
       "18  913.1045  913.1082  913.1095  913.1085  913.1095  913.1092  913.1074\n",
       "19  902.3059  902.3097  902.3111  902.3100  902.3110  902.3107  902.3088\n",
       "20  893.1608  893.1648  893.1663  893.1651  893.1660  893.1657  893.1637\n",
       "21  885.5886  885.5928  885.5944  885.5931  885.5940  885.5936  885.5916\n",
       "22  879.5102  879.5147  879.5163  879.5150  879.5158  879.5154  879.5134\n",
       "23  874.8489  874.8536  874.8552  874.8538  874.8547  874.8542  874.8521\n",
       "24  871.5300  871.5349  871.5366  871.5352  871.5360  871.5356  871.5334\n",
       "25  869.4816  869.4867  869.4885  869.4870  869.4878  869.4874  869.4852\n",
       "26  868.6342  868.6395  868.6414  868.6398  868.6407  868.6402  868.6380\n",
       "27  868.9208  868.9263  868.9283  868.9267  868.9276  868.9271  868.9249\n",
       "28  870.2772  870.2829  870.2850  870.2833  870.2842  870.2837  870.2814\n",
       "29  872.6414  872.6473  872.6495  872.6478  872.6487  872.6481  872.6459\n",
       "30  875.9541  875.9603  875.9626  875.9608  875.9617  875.9612  875.9589\n",
       "   V8        V9        V10       Y    \n",
       "1  2929.0903 2929.0897 2929.0894 TRUE \n",
       "2  1658.2525 1658.0376 1657.7735 TRUE \n",
       "3  1279.7489 1279.6423 1279.4628 TRUE \n",
       "4  1253.9264 1253.8883 1253.8126 TRUE \n",
       "5  1233.9667 1233.9699 1233.9660 TRUE \n",
       "6  1202.3927 1202.4127 1202.4369 TRUE \n",
       "7  1165.8569 1165.8761 1165.9002 TRUE \n",
       "8  1130.7253 1130.7381 1130.7533 TRUE \n",
       "9  1098.2860 1098.2932 1098.3005 TRUE \n",
       "10 1068.6864 1068.6902 1068.6928 TRUE \n",
       "11 1041.6874 1041.6893 1041.6893 TRUE \n",
       "12 1017.0784 1017.0791 1017.0776 TRUE \n",
       "13  994.7012  994.7011  994.6983 TRUE \n",
       "14  974.4479  974.4469  974.4430 TRUE \n",
       "15  956.2365  956.2348  956.2299 TRUE \n",
       "16  939.9936  939.9912  939.9854 TRUE \n",
       "17  925.6442  925.6412  925.6347 TRUE \n",
       "18  913.1104  913.1069  913.0996 FALSE\n",
       "19  902.3115  902.3075  902.2996 FALSE\n",
       "20  893.1663  893.1618  893.1532 FALSE\n",
       "21  885.5939  885.5890  885.5799 FALSE\n",
       "22  879.5155  879.5102  879.5005 FALSE\n",
       "23  874.8541  874.8485  874.8383 FALSE\n",
       "24  871.5352  871.5292  871.5185 FALSE\n",
       "25  869.4869  869.4805  869.4693 FALSE\n",
       "26  868.6395  868.6328  868.6211 FALSE\n",
       "27  868.9262  868.9192  868.9070 FALSE\n",
       "28  870.2827  870.2753  870.2627 FALSE\n",
       "29  872.6470  872.6393  872.6262 FALSE\n",
       "30  875.9599  875.9519  875.9384 FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = read.csv('../../output/X.txt',header=F)\n",
    "Y = apply(read.csv('../../output/Y.txt',header=F),1,sum)\n",
    "\n",
    "Y = factor(Y>9000)\n",
    "data2 <- data.frame(X, Y)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in lda.default(x, grouping, ...):\n",
      "variables are collinear"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " abcrf(formula = Y ~ ., data = data2, ntree = 100) \n",
       "includes the axes of a preliminary LDA\n",
       "\n",
       "Number of simulations: 1\n",
       "Out-of-bag prior error rate: 3.3333%\n",
       "\n",
       "Confusion matrix:\n",
       "      FALSE TRUE class.error\n",
       "FALSE    13    0  0.00000000\n",
       "TRUE      1   16  0.05882353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.rf1 <- abcrf(Y~., data = data2, ntree=100)\n",
    "model.rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(abcrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = seq(-.9,.9,.1)\n",
    "Data.healthy=data.frame(matrix(ncol = 80, nrow = 1))\n",
    "n=0\n",
    "for(i in sapply(s,function(x)paste(\"tmp/s=\", format(x, nsmall = 2),\",diam_narrow=0.000000.csv\",sep=\"\"))){\n",
    "    n=n+1\n",
    "    x=read.csv(i,header=FALSE)\n",
    "    stopifnot(dim(healthydata)[2]==length(c(data.matrix(x))))\n",
    "    Data.healthy[n,]=c(data.matrix(x))\n",
    "}\n",
    "                \n",
    "Data.sick=data.frame(matrix(ncol = 80, nrow = 1))\n",
    "n=0\n",
    "for(i in sapply(s,function(x)paste(\"tmp/s=\", format(x, nsmall = 2),\",diam_narrow=0.000000.csv\",sep=\"\"))){\n",
    "    n=n+1\n",
    "    x=read.csv(i,header=FALSE)\n",
    "    stopifnot(dim(healthydata)[2]==length(c(data.matrix(x))))\n",
    "    Data.sick[n,]=c(data.matrix(x))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.sick$healthy=0\n",
    "Data.healthy$healthy=1\n",
    "\n",
    "data3=rbind(Data.healthy,Data.sick)\n",
    "data3$healthy=factor(data3$healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       " abcrf(formula = healthy ~ ., data = data3, lda = FALSE, ntree = 100) \n",
       "Number of simulations: 1\n",
       "Out-of-bag prior error rate: 100%\n",
       "\n",
       "Confusion matrix:\n",
       "   0  1 class.error\n",
       "0  0 19           1\n",
       "1 19  0           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.rf3 <- abcrf(healthy~., data = data3, ntree=100,lda=FALSE)\n",
    "model.rf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$call\n",
       "abcrf(formula = healthy ~ ., data = data3, lda = FALSE, ntree = 100)\n",
       "\n",
       "$lda\n",
       "[1] FALSE\n",
       "\n",
       "$formula\n",
       "healthy ~ .\n",
       "\n",
       "$group\n",
       "list()\n",
       "\n",
       "$model.rf\n",
       "Ranger result\n",
       "\n",
       "Call:\n",
       " ranger(formula, data, num.trees = ntree, sample.fraction = sampsize/nrow(data),      num.threads = ncores, keep.inbag = TRUE, importance = \"impurity\",      ...) \n",
       "\n",
       "Type:                             Classification \n",
       "Number of trees:                  100 \n",
       "Sample size:                      38 \n",
       "Number of independent variables:  80 \n",
       "Mtry:                             8 \n",
       "Target node size:                 1 \n",
       "Variable importance mode:         impurity \n",
       "Splitrule:                        gini \n",
       "OOB prediction error:             100.00 % \n",
       "\n",
       "$model.lda\n",
       "NULL\n",
       "\n",
       "$prior.err\n",
       "[1] 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unclass(model.rf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=data3[sample(nrow(data3)),]\n",
    "training=data4[1:26,]\n",
    "test=data4[27:38,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   selected model votes model1 votes model2 post.proba\n",
       "1            TRUE           43          457     0.7610\n",
       "2            TRUE          144          356     0.2870\n",
       "3           FALSE          402           98     0.0565\n",
       "4            TRUE          114          386     0.0615\n",
       "5           FALSE          468           32     0.9285\n",
       "6           FALSE          417           83     0.7145\n",
       "7           FALSE          425           75     0.6345\n",
       "8           FALSE          484           16     0.9385\n",
       "9            TRUE          214          286     0.3770\n",
       "10           TRUE           31          469     0.8310\n",
       "11           TRUE          214          286     0.3770\n",
       "12          FALSE          453           47     0.8185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.rf4 <- abcrf(healthy~., data = training,lda=FALSE)\n",
    "predict(model.rf4, test, training, ntree=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \n",
       "        FALSE TRUE\n",
       "  FALSE     0    5\n",
       "  TRUE      6    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(ranger)\n",
    "model = ranger(healthy ~ ., data = training)\n",
    "pred <- predict(model, data = test)\n",
    "table(test$healthy, pred$predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(snp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
